{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This project's goal is to extract data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries needed to scrape\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "# This will be heavily commented as you can imagine it's easy to forget a python library lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "res = requests.get(\"https://www.themoviedb.org/movie\", headers=needed_headers)\n",
    "res.status_code\n",
    "# An exit status of 200 means OK :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the BeautifulSoup class\n",
    "# also im using lxml instead html.parser lets see how that goes\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "# We won't call soup for our own sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Movies \n"
     ]
    }
   ],
   "source": [
    "web_content = soup.get_text().strip()\n",
    "# using .strip() right now gets rid of trailing whitespaces but not leading??? wtf? will figure out\n",
    "print(web_content[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Popular Movies — The Movie Database (TMDB)</title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the title of the parsed web page \n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Popular Movies — The Movie Database (TMDB)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another method of fetching the title\n",
    "soup.select(\"title\")[0].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing initial task with the help of functions..\n",
    "def vaccum(url: str) -> BeautifulSoup:\n",
    "    try:\n",
    "        # I am not a robot\n",
    "        needed_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        res_func = requests.get(url,headers=needed_headers)\n",
    "\n",
    "        # Raise exception if status code is 5xx or 4xx\n",
    "        res_func.raise_for_status()\n",
    "\n",
    "        return BeautifulSoup(res_func.text, \"lxml\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Catch all request-related errors \n",
    "        print(f\"An Error occured!: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        print(\"Excecution FIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excecution FIN\n"
     ]
    }
   ],
   "source": [
    "# test case 1: a working url\n",
    "vaccumed = vaccum(\"https://www.themoviedb.org/movie\")\n",
    "# This works, won't call it for obvious reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Error occured!: HTTPSConnectionPool(host='www.themovipepepe.org', port=443): Max retries exceeded with url: /what (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002F7067E4C10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Excecution FIN\n"
     ]
    }
   ],
   "source": [
    "# test case 2: malformed/incorrect URLS\n",
    "vaccum(\"https://www.themovipepepe.org/what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red One'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the name of the first movie\n",
    "first_movie = soup.select(\".content h2\")[3].getText()\n",
    "first_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User score of the movie: Red One is 70%\n"
     ]
    }
   ],
   "source": [
    "#  Extracting User rating of the first movie\n",
    "span_class = soup.select_one(\".user_score_chart .icon\")['class'][1]\n",
    "span_class\n",
    "perc1 = span_class.split(\"icon-r\")[1]\n",
    "print(f\"User score of the movie: {first_movie} is {perc1}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie/845781'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're gonna use regex for extracting the part of the url following the string “https://www.themoviedb.org/” \n",
    "text = str(soup.select(\".content h2\"))\n",
    "match = re.search(r'movie/\\d\\d\\d\\d\\d\\d',text)\n",
    "match.group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red One',\n",
       " 'Venom: The Last Dance',\n",
       " 'Moana 2',\n",
       " 'Mufasa: The Lion King',\n",
       " 'Sonic the Hedgehog 3',\n",
       " 'Elevation',\n",
       " 'The Price of Money: A Largo Winch Adventure',\n",
       " 'कैरी-ऑन',\n",
       " 'Kraven the Hunter',\n",
       " 'Absolution',\n",
       " 'Gladiator II',\n",
       " 'The Wild Robot',\n",
       " 'Heretic',\n",
       " 'वह यादगार क्रिसमस',\n",
       " 'Armor',\n",
       " 'The Substance',\n",
       " 'Terrifier 3',\n",
       " 'My Fault',\n",
       " 'Miraculous World, London: At the Edge of Time',\n",
       " 'Weekend in Taipei']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Titles of all the movies on the page as a Python list\n",
    "def title_grabber(soup: BeautifulSoup) -> list:\n",
    "    titles = []\n",
    "    movies = soup.select(\".content h2\")[3:]\n",
    "    for movie in movies:\n",
    "        a_tag = movie.find(\"a\", title = True)\n",
    "        if a_tag:\n",
    "            titles.append(a_tag[\"title\"])\n",
    "    return titles\n",
    "    \n",
    "        \n",
    "title_grabber(vaccumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70',\n",
       " '68',\n",
       " '71',\n",
       " '70',\n",
       " '70',\n",
       " '79',\n",
       " '61',\n",
       " '57',\n",
       " '63',\n",
       " '58',\n",
       " '61',\n",
       " '67',\n",
       " '84',\n",
       " '55',\n",
       " '73',\n",
       " '72',\n",
       " '77',\n",
       " '75',\n",
       " '79',\n",
       " '72']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User ratings of all the movies on the page as a Python list \n",
    "def rating_grabber(soup: BeautifulSoup) -> list:\n",
    "    user_score = []\n",
    "    scores = soup.select(\".content .user_score_chart\")\n",
    "\n",
    "    for score in scores:\n",
    "        percent = score[\"data-percent\"]\n",
    "        user_score.append(percent)\n",
    "\n",
    "    return user_score\n",
    "rating_grabber(vaccumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2>Sort</h2>,\n",
       " <h2>Where To Watch <span>103</span></h2>,\n",
       " <h2>Filters</h2>,\n",
       " <h2><a href=\"/movie/845781-red-one\" title=\"Red One\">Red One</a></h2>,\n",
       " <h2><a href=\"/movie/912649-venom-the-last-dance\" title=\"Venom: The Last Dance\">Venom: The Last Dance</a></h2>,\n",
       " <h2><a href=\"/movie/762509-mufasa-the-lion-king\" title=\"Mufasa: The Lion King\">Mufasa: The Lion King</a></h2>,\n",
       " <h2><a href=\"/movie/1241982-moana-2\" title=\"Moana 2\">Moana 2</a></h2>,\n",
       " <h2><a href=\"/movie/1005331-carry-on\" title=\"Carry-On\">Carry-On</a></h2>,\n",
       " <h2><a href=\"/movie/939243-sonic-the-hedgehog-3\" title=\"Sonic the Hedgehog 3\">Sonic the Hedgehog 3</a></h2>,\n",
       " <h2><a href=\"/movie/1043905-dirty-angels\" title=\"Dirty Angels\">Dirty Angels</a></h2>,\n",
       " <h2><a href=\"/movie/1000075-largo-winch-le-prix-de-l-argent\" title=\"The Price of Money: A Largo Winch Adventure\">The Price of Money: A Largo Winch Adventure</a></h2>,\n",
       " <h2><a href=\"/movie/1035048-elevation\" title=\"Elevation\">Elevation</a></h2>,\n",
       " <h2><a href=\"/movie/539972-kraven-the-hunter\" title=\"Kraven the Hunter\">Kraven the Hunter</a></h2>,\n",
       " <h2><a href=\"/movie/974453-absolution\" title=\"Absolution\">Absolution</a></h2>,\n",
       " <h2><a href=\"/movie/558449-gladiator-ii\" title=\"Gladiator II\">Gladiator II</a></h2>,\n",
       " <h2><a href=\"/movie/1184918-the-wild-robot\" title=\"The Wild Robot\">The Wild Robot</a></h2>,\n",
       " <h2><a href=\"/movie/1182387-armor\" title=\"Armor\">Armor</a></h2>,\n",
       " <h2><a href=\"/movie/645757-that-christmas\" title=\"That Christmas\">That Christmas</a></h2>,\n",
       " <h2><a href=\"/movie/933260-the-substance\" title=\"The Substance\">The Substance</a></h2>,\n",
       " <h2><a href=\"/movie/533535-deadpool-wolverine\" title=\"Deadpool &amp; Wolverine\">Deadpool &amp; Wolverine</a></h2>,\n",
       " <h2><a href=\"/movie/1299652-watchmen-chapter-ii\" title=\"Watchmen: Chapter II\">Watchmen: Chapter II</a></h2>,\n",
       " <h2><a href=\"/movie/1010581-culpa-mia\" title=\"My Fault\">My Fault</a></h2>,\n",
       " <h2><a href=\"/movie/1138194-heretic\" title=\"Heretic\">Heretic</a></h2>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\".content h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie/845781',\n",
       " 'movie/912649',\n",
       " 'movie/762509',\n",
       " 'movie/124198',\n",
       " 'movie/100533',\n",
       " 'movie/939243',\n",
       " 'movie/104390',\n",
       " 'movie/100007',\n",
       " 'movie/103504',\n",
       " 'movie/539972',\n",
       " 'movie/974453',\n",
       " 'movie/558449',\n",
       " 'movie/118491',\n",
       " 'movie/118238',\n",
       " 'movie/645757',\n",
       " 'movie/933260',\n",
       " 'movie/533535',\n",
       " 'movie/129965',\n",
       " 'movie/101058',\n",
       " 'movie/113819']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML content of all the individual pages of movies collected into a Python list\n",
    "def html_content(soup: BeautifulSoup) -> list:\n",
    "    my_content = str(soup.select(\".content h2\"))\n",
    "    my_list = []\n",
    "\n",
    "    stuff = re.findall(r\"movie/\\d\\d\\d\\d\\d\\d\", my_content)\n",
    "    my_list.extend(stuff)\n",
    "\n",
    "    return my_list\n",
    "   \n",
    "html_content(vaccumed)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
