{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries needed to scrape\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "# This will be heavily commented as you can imagine it's easy to forget a python library lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "res = requests.get(\"https://www.themoviedb.org/movie\", headers=needed_headers)\n",
    "res.status_code\n",
    "# An exit status of 200 means OK :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the BeautifulSoup class\n",
    "# also im going to be using lxml instead html.parser lets see how that goes\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "# We won't call soup for our own sanity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Movies \n"
     ]
    }
   ],
   "source": [
    "web_content = soup.get_text().strip()\n",
    "# using .strip() right now gets rid of trailing whitespaces but not leading??? wtf? will figure out\n",
    "print(web_content[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the title of the web page using various methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Popular Movies — The Movie Database (TMDB)</title>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting title\n",
    "soup.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Popular Movies — The Movie Database (TMDB)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another method of fetching the title\n",
    "soup.select(\"title\")[0].getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use functions to help ease our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing initial task with the help of functional stuff\n",
    "def vaccum(url: str) -> BeautifulSoup:\n",
    "    try:\n",
    "        # I am not a robot lmao\n",
    "        needed_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        res_func = requests.get(url,headers=needed_headers)\n",
    "\n",
    "        # Raise exception if status code is 5xx or 4xx\n",
    "        res_func.raise_for_status()\n",
    "\n",
    "        return BeautifulSoup(res_func.text, \"lxml\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Catch all request-related errors \n",
    "        print(f\"An Error occured!: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        print(\"Excecution FIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excecution FIN\n"
     ]
    }
   ],
   "source": [
    "# test case 1: a working url\n",
    "vaccumed = vaccum(\"https://www.themoviedb.org/movie\")\n",
    "# This works, won't call it for obvious reasons haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Error occured!: HTTPSConnectionPool(host='www.themovipepepe.org', port=443): Max retries exceeded with url: /what (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000242ABA3C980>: Failed to resolve 'www.themovipepepe.org' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Excecution FIN\n"
     ]
    }
   ],
   "source": [
    "# test case 2: malformed/incorrect URLs\n",
    "vaccum(\"https://www.themovipepepe.org/what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sonic the Hedgehog 3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the name of the first movie\n",
    "first_movie = soup.select(\".content h2\")[3].getText()\n",
    "first_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User score of the movie: Sonic the Hedgehog 3 is 79%\n"
     ]
    }
   ],
   "source": [
    "# Extracting User rating of the first movie\n",
    "span_class = soup.select_one(\".user_score_chart .icon\")['class'][1]\n",
    "span_class\n",
    "perc1 = span_class.split(\"icon-r\")[1]\n",
    "print(f\"User score of the movie: {first_movie} is {perc1}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie/939243'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're gonna use regex for extracting the part of the url following the string “https://www.themoviedb.org/” \n",
    "text = str(soup.select(\".content h2\"))\n",
    "match = re.search(r'movie/\\d\\d\\d\\d\\d\\d',text)\n",
    "match.group()\n",
    "# This is going to help us later (i think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sonic the Hedgehog 3',\n",
       " 'Kraven the Hunter',\n",
       " 'बैक इन ऐक्शन',\n",
       " 'Nosferatu',\n",
       " 'Mufasa: The Lion King',\n",
       " 'Moana 2',\n",
       " 'Devara: Part 1',\n",
       " 'Venom: The Last Dance',\n",
       " 'Gladiator II',\n",
       " 'The Gardener',\n",
       " 'Wicked',\n",
       " 'Kingdom IV: Return of the Great General',\n",
       " 'The Substance',\n",
       " 'Alarum',\n",
       " 'River of Blood',\n",
       " 'यॉर फ़ॉल्ट',\n",
       " 'Werewolves',\n",
       " 'Aftermath',\n",
       " 'Red One',\n",
       " 'The Lord of the Rings: The War of the Rohirrim']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the title of all the movies\n",
    "def title_grabber(soup: BeautifulSoup) -> list:\n",
    "    titles = []\n",
    "    movies = soup.select(\".content h2\")[3:]\n",
    "    for movie in movies:\n",
    "        a_tag = movie.find(\"a\", title = True)\n",
    "        if a_tag:\n",
    "            titles.append(a_tag[\"title\"])\n",
    "    return titles\n",
    "    \n",
    "        \n",
    "title_grabber(vaccumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79',\n",
       " '66',\n",
       " '67',\n",
       " '66',\n",
       " '75',\n",
       " '70',\n",
       " '72',\n",
       " '68',\n",
       " '68',\n",
       " '49',\n",
       " '69',\n",
       " '71',\n",
       " '71',\n",
       " '59',\n",
       " '65',\n",
       " '72',\n",
       " '63',\n",
       " '63',\n",
       " '71',\n",
       " '66']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the user ratings of all the movies in a page\n",
    "def rating_grabber(soup: BeautifulSoup) -> list:\n",
    "    user_score = []\n",
    "    scores = soup.select(\".content .user_score_chart\")\n",
    "\n",
    "    for score in scores:\n",
    "        percent = score[\"data-percent\"]\n",
    "        user_score.append(percent)\n",
    "\n",
    "    return user_score\n",
    "rating_grabber(vaccumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2>Sort</h2>,\n",
       " <h2>Where To Watch <span>71</span></h2>,\n",
       " <h2>Filters</h2>,\n",
       " <h2><a href=\"/movie/939243-sonic-the-hedgehog-3\" title=\"Sonic the Hedgehog 3\">Sonic the Hedgehog 3</a></h2>,\n",
       " <h2><a href=\"/movie/539972-kraven-the-hunter\" title=\"Kraven the Hunter\">Kraven the Hunter</a></h2>,\n",
       " <h2><a href=\"/movie/993710-back-in-action\" title=\"बैक इन ऐक्शन\">बैक इन ऐक्शन</a></h2>,\n",
       " <h2><a href=\"/movie/426063-nosferatu\" title=\"Nosferatu\">Nosferatu</a></h2>,\n",
       " <h2><a href=\"/movie/762509-mufasa-the-lion-king\" title=\"Mufasa: The Lion King\">Mufasa: The Lion King</a></h2>,\n",
       " <h2><a href=\"/movie/1241982-moana-2\" title=\"Moana 2\">Moana 2</a></h2>,\n",
       " <h2><a href=\"/movie/811941-part-1\" title=\"Devara: Part 1\">Devara: Part 1</a></h2>,\n",
       " <h2><a href=\"/movie/912649-venom-the-last-dance\" title=\"Venom: The Last Dance\">Venom: The Last Dance</a></h2>,\n",
       " <h2><a href=\"/movie/558449-gladiator-ii\" title=\"Gladiator II\">Gladiator II</a></h2>,\n",
       " <h2><a href=\"/movie/1255788-le-jardinier\" title=\"The Gardener\">The Gardener</a></h2>,\n",
       " <h2><a href=\"/movie/402431-wicked\" title=\"Wicked\">Wicked</a></h2>,\n",
       " <h2><a href=\"/movie/1241320\" title=\"Kingdom IV: Return of the Great General\">Kingdom IV: Return of the Great General</a></h2>,\n",
       " <h2><a href=\"/movie/933260-the-substance\" title=\"The Substance\">The Substance</a></h2>,\n",
       " <h2><a href=\"/movie/1249289-alarum\" title=\"Alarum\">Alarum</a></h2>,\n",
       " <h2><a href=\"/movie/1222064-river-of-blood\" title=\"River of Blood\">River of Blood</a></h2>,\n",
       " <h2><a href=\"/movie/1156593-culpa-tuya\" title=\"यॉर फ़ॉल्ट\">यॉर फ़ॉल्ट</a></h2>,\n",
       " <h2><a href=\"/movie/970450-werewolves\" title=\"Werewolves\">Werewolves</a></h2>,\n",
       " <h2><a href=\"/movie/1081012-aftermath\" title=\"Aftermath\">Aftermath</a></h2>,\n",
       " <h2><a href=\"/movie/845781-red-one\" title=\"Red One\">Red One</a></h2>,\n",
       " <h2><a href=\"/movie/839033-the-lord-of-the-rings-the-war-of-the-rohirrim\" title=\"The Lord of the Rings: The War of the Rohirrim\">The Lord of the Rings: The War of the Rohirrim</a></h2>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\".content h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie/939243',\n",
       " 'movie/539972',\n",
       " 'movie/993710',\n",
       " 'movie/426063',\n",
       " 'movie/762509',\n",
       " 'movie/124198',\n",
       " 'movie/811941',\n",
       " 'movie/912649',\n",
       " 'movie/558449',\n",
       " 'movie/125578',\n",
       " 'movie/402431',\n",
       " 'movie/124132',\n",
       " 'movie/933260',\n",
       " 'movie/124928',\n",
       " 'movie/122206',\n",
       " 'movie/115659',\n",
       " 'movie/970450',\n",
       " 'movie/108101',\n",
       " 'movie/845781',\n",
       " 'movie/839033']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the HTML golddd of all the individual pages of movies\n",
    "def html_content(soup: BeautifulSoup) -> list:\n",
    "    my_content = str(soup.select(\".content h2\"))\n",
    "    my_list = []\n",
    "\n",
    "    stuff = re.findall(r\"movie/\\d\\d\\d\\d\\d\\d\", my_content)\n",
    "    my_list.extend(stuff)\n",
    "\n",
    "    return my_list\n",
    "   \n",
    "html_content(vaccumed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"multi_select text\" id=\"with_genres\" name=\"with_genres[]\">\n",
       "<li data-value=\"28\"><a class=\"no_click\" href=\"/discover/movie?with_genres=28\">Action</a></li>\n",
       "<li data-value=\"12\"><a class=\"no_click\" href=\"/discover/movie?with_genres=12\">Adventure</a></li>\n",
       "<li data-value=\"16\"><a class=\"no_click\" href=\"/discover/movie?with_genres=16\">Animation</a></li>\n",
       "<li data-value=\"35\"><a class=\"no_click\" href=\"/discover/movie?with_genres=35\">Comedy</a></li>\n",
       "<li data-value=\"80\"><a class=\"no_click\" href=\"/discover/movie?with_genres=80\">Crime</a></li>\n",
       "<li data-value=\"99\"><a class=\"no_click\" href=\"/discover/movie?with_genres=99\">Documentary</a></li>\n",
       "<li data-value=\"18\"><a class=\"no_click\" href=\"/discover/movie?with_genres=18\">Drama</a></li>\n",
       "<li data-value=\"10751\"><a class=\"no_click\" href=\"/discover/movie?with_genres=10751\">Family</a></li>\n",
       "<li data-value=\"14\"><a class=\"no_click\" href=\"/discover/movie?with_genres=14\">Fantasy</a></li>\n",
       "<li data-value=\"36\"><a class=\"no_click\" href=\"/discover/movie?with_genres=36\">History</a></li>\n",
       "<li data-value=\"27\"><a class=\"no_click\" href=\"/discover/movie?with_genres=27\">Horror</a></li>\n",
       "<li data-value=\"10402\"><a class=\"no_click\" href=\"/discover/movie?with_genres=10402\">Music</a></li>\n",
       "<li data-value=\"9648\"><a class=\"no_click\" href=\"/discover/movie?with_genres=9648\">Mystery</a></li>\n",
       "<li data-value=\"10749\"><a class=\"no_click\" href=\"/discover/movie?with_genres=10749\">Romance</a></li>\n",
       "<li data-value=\"878\"><a class=\"no_click\" href=\"/discover/movie?with_genres=878\">Science Fiction</a></li>\n",
       "<li data-value=\"10770\"><a class=\"no_click\" href=\"/discover/movie?with_genres=10770\">TV Movie</a></li>\n",
       "<li data-value=\"53\"><a class=\"no_click\" href=\"/discover/movie?with_genres=53\">Thriller</a></li>\n",
       "<li data-value=\"10752\"><a class=\"no_click\" href=\"/discover/movie?with_genres=10752\">War</a></li>\n",
       "<li data-value=\"37\"><a class=\"no_click\" href=\"/discover/movie?with_genres=37\">Western</a></li>\n",
       "</ul>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\".multi_select\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Family',\n",
       " 'Fantasy',\n",
       " 'History',\n",
       " 'Horror',\n",
       " 'Music',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Science Fiction',\n",
       " 'TV Movie',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the genres of the movies\n",
    "def genre_grabber(soup: BeautifulSoup) -> list:\n",
    "    genres = soup.select(\".multi_select\")[-2]\n",
    "    my_genres = []\n",
    "    for gen in genres.find_all(\"li\"): # found them in list item using inspect\n",
    "        a_tag = gen.find(\"a\")\n",
    "        if a_tag:\n",
    "            my_genres.append(a_tag.text.strip())\n",
    "    return my_genres\n",
    "genre_grabber(vaccumed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='www.themoviedb.org', port=443): Max retries exceeded with url: /939243 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000242AEC931D0>, 'Connection to www.themoviedb.org timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    200\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    202\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    203\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    692\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    694\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:208\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x00000242AEC931D0>, 'Connection to www.themoviedb.org timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.themoviedb.org', port=443): Max retries exceeded with url: /939243 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000242AEC931D0>, 'Connection to www.themoviedb.org timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.themoviedb.org/939243\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers\u001b[38;5;241m=\u001b[39mneeded_headers)\n\u001b[0;32m      2\u001b[0m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.people\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\ther0\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='www.themoviedb.org', port=443): Max retries exceeded with url: /939243 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000242AEC931D0>, 'Connection to www.themoviedb.org timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "res = requests.get(\"https://www.themoviedb.org/939243\", headers=needed_headers)\n",
    "soup.select(\".people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the casts of all the movies\n",
    "def cast_grabber(soup: BeautifulSoup) -> list:\n",
    "    \n",
    "    \n",
    "    pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
